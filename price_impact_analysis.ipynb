{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8ba4aa",
   "metadata": {},
   "source": [
    "# From Square-Root Law to Dynamic Trade Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90504d2c",
   "metadata": {},
   "source": [
    "## 1. The dataset\n",
    "\n",
    "From binance cryptocurrency api via the binance-LOB repository (https://github.com/pfei-sa/binance-LOB/tree/main)\n",
    "\n",
    "Quotes data with a depth of 100 into the LOB timestamp, ask price, ask volume, bid price, bid volume, midpoint, spread\n",
    "\n",
    "Trades data withtimestamp, price, volume, trade sign (-1 = sell, 1 = buy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99cfdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap, random\n",
    "import jax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134e6850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Median: 0.000050 BTC\n",
      "     Zero volumes: 0 (0.00%)\n",
      "   Scale factor: 20000.0\n",
      "     trade_id      price   volume  quote_volume                     timestamp  \\\n",
      "0  5129304097  112546.35  0.00018     20.258343 1970-01-21 07:16:19.200039304   \n",
      "1  5129304098  112546.35  0.00005      5.627318 1970-01-21 07:16:19.200046122   \n",
      "2  5129304099  112546.35  0.00005      5.627318 1970-01-21 07:16:19.200046122   \n",
      "3  5129304100  112546.35  0.00005      5.627318 1970-01-21 07:16:19.200046122   \n",
      "4  5129304101  112546.35  0.00005      5.627318 1970-01-21 07:16:19.200046122   \n",
      "\n",
      "   trade_sign  volume_normalized  log_volume  sqrt_volume  \n",
      "0           1                3.6    1.280934     1.897367  \n",
      "1           1                1.0    0.000000     1.000000  \n",
      "2           1                1.0    0.000000     1.000000  \n",
      "3           1                1.0    0.000000     1.000000  \n",
      "4           1                1.0    0.000000     1.000000  \n",
      "(7408539, 9)\n"
     ]
    }
   ],
   "source": [
    "trades_df = pd.concat([\n",
    "    pd.read_csv(file, header=None, names=[\n",
    "        'trade_id', 'price', 'volume', 'quote_volume', \n",
    "        'timestamp', 'is_buyer_maker', 'is_best_match'\n",
    "    ]) for file in glob.glob(os.path.join(\"data/binance_raw\", \"BTCUSDT-trades*.csv\"))\n",
    "], ignore_index=True)\n",
    "\n",
    "trades_df['timestamp'] = pd.to_datetime(trades_df['timestamp'], unit='ns')\n",
    "trades_df['price'] = trades_df['price'].astype(float)\n",
    "trades_df['volume'] = trades_df['volume'].astype(float)\n",
    "trades_df['trade_sign'] = trades_df['is_buyer_maker'].apply(lambda x: -1 if x else 1)\n",
    "trades_df = trades_df.drop(columns=['is_buyer_maker', 'is_best_match'], axis=1)\n",
    "\n",
    "volumes = trades_df['volume']\n",
    "print(f\"     Median: {np.median(volumes):.6f} BTC\")\n",
    "print(f\"     Zero volumes: {np.sum(volumes == 0)} ({100*np.mean(volumes == 0):.2f}%)\")\n",
    "median_volume = np.median(volumes[volumes > 0])\n",
    "scale_factor = 1.0 / median_volume\n",
    "trades_clean = trades_df.copy()\n",
    "trades_clean['volume_normalized'] = trades_clean['volume'] * scale_factor\n",
    "print(\"   Scale factor:\", scale_factor)\n",
    "trades_clean['log_volume'] = np.log(trades_clean['volume_normalized'])\n",
    "trades_clean['sqrt_volume'] = np.sqrt(trades_clean['volume_normalized'])\n",
    "\n",
    "print(trades_clean.head())\n",
    "print(trades_clean.shape)\n",
    "\"\"\"\n",
    "ohlvc_df = pd.concat([\n",
    "    pd.read_csv(file, header=None, names=[\n",
    "                'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "                'close_time', 'quote_volume', 'count', 'taker_buy_volume',\n",
    "                'taker_buy_quote_volume', 'ignore'\n",
    "    ]) for file in glob.glob(os.path.join(\"data/binance_raw\", \"BTCUSDT-1s*.csv\"))\n",
    "], ignore_index=True)\n",
    "\n",
    "ohlvc_df['open_time'] = pd.to_datetime(ohlvc_df['open_time'], unit='ns')\n",
    "ohlvc_df['close_time'] = pd.to_datetime(ohlvc_df['close_time'], unit='ns')\n",
    "ohlvc_df['midpoint'] = (ohlvc_df['high'] + ohlvc_df['low'])/2\n",
    "ohlvc_df['spread'] = 2 * (ohlvc_df['high'] - ohlvc_df['low'])\n",
    "\"\"\"\n",
    "prices = trades_clean['price'].values\n",
    "signs = trades_clean['trade_sign'].values\n",
    "volumes = trades_clean['volume_normalized'].values\n",
    "log_volumes = trades_clean['log_volume'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761577d",
   "metadata": {},
   "source": [
    "## 1. Baseline Implementation\n",
    "- Square-Root Law: ΔP = Y σ√(Q/V)\n",
    "- Parameter estimation and statistical validation\n",
    "- Identify systematic deviations and failure modes\n",
    "\n",
    "R(ℓ) measures how much, on average, the price moves up conditioned to a buy\n",
    "order at time 0 (or a sell order moves the price down) a time ℓ later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bc02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def response(prices, signs, max_lag):\n",
    "\n",
    "    n_trades = len(prices)\n",
    "    lags = np.arange(1, min(max_lag + 1, n_trades // 2))\n",
    "    response = np.zeros(len(lags))\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        price_diffs = prices[lag:] - prices[:-lag]\n",
    "        trade_signs = signs[:-lag]\n",
    "        \n",
    "        response[i] = np.mean(price_diffs * trade_signs)\n",
    "    \n",
    "    return lags, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lag = 1000\n",
    "\n",
    "lags, response_func = response(prices, signs, max_lag)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.loglog(lags, response_func, 'ko-', linewidth=2, markersize=4, label='R(ℓ)')\n",
    "plt.xlabel('Time (Trades)', fontsize=12)\n",
    "plt.ylabel('R(ℓ)', fontsize=12)\n",
    "plt.title('Response Function R(ℓ)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd885018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditioned_response(prices, signs, volumes, log_vols, lags, n_vol_bins, vol_percentiles):\n",
    "\n",
    "    n_trades = len(prices)\n",
    "\n",
    "    # Log-spaced volume bins\n",
    "    vol_min, vol_max = np.percentile(log_vols, vol_percentiles)\n",
    "    vol_bins = np.logspace(vol_min, vol_max, n_vol_bins + 1, base=np.e)\n",
    "\n",
    "    response_matrix = np.full((len(lags), n_vol_bins), np.nan)\n",
    "    vol_centers = np.zeros(n_vol_bins)    \n",
    "\n",
    "    for vol_idx in range(n_vol_bins):\n",
    "        # Find trades in this volume bin\n",
    "        vol_mask = (volumes >= vol_bins[vol_idx]) & (volumes < vol_bins[vol_idx + 1])\n",
    "        vol_centers[vol_idx] = np.sqrt(vol_bins[vol_idx] * vol_bins[vol_idx + 1])\n",
    "        \n",
    "        if np.sum(vol_mask) < 50:  # Skip bins with few trades\n",
    "            continue\n",
    "        \n",
    "        vol_indices = np.where(vol_mask)[0]\n",
    "        \n",
    "        for i, lag in enumerate(lags):\n",
    "            valid_indices = vol_indices[vol_indices < n_trades - lag]\n",
    "            \n",
    "            if len(valid_indices) < 10:\n",
    "                continue\n",
    "                \n",
    "            # response\n",
    "            price_diffs = prices[valid_indices + lag] - prices[valid_indices]\n",
    "            trade_signs = signs[valid_indices]\n",
    "            response_matrix[i, vol_idx] = np.mean(price_diffs * trade_signs)\n",
    "\n",
    "    return {\n",
    "        'lags': lags,\n",
    "        'vol_centers': vol_centers,\n",
    "        'vol_bins': vol_bins,\n",
    "        'response_matrix': response_matrix,\n",
    "        'log_vol_centers': np.log(vol_centers)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_data = conditioned_response(prices, signs, volumes, log_volumes, lags, n_vol_bins=8, vol_percentiles=(5, 95))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(vol_data['vol_centers'])))\n",
    "\n",
    "for vol_idx, (vol_center, color) in enumerate(zip(vol_data['vol_centers'], colors)):\n",
    "    response_vol = vol_data['response_matrix'][:, vol_idx]\n",
    "    valid_mask = ~np.isnan(response_vol)\n",
    "    \n",
    "    if np.sum(valid_mask) > 10:\n",
    "        log_vol = np.log(vol_center)\n",
    "        label = f'log V=[{log_vol:.1f}]'\n",
    "        \n",
    "        scaled_response = response_vol / np.log(vol_center)\n",
    "        \n",
    "        plt.loglog(lags[valid_mask], scaled_response[valid_mask], \n",
    "                    'o-', color=color, linewidth=1.5, markersize=3,\n",
    "                    alpha=0.7, label=label) \n",
    "\n",
    "plt.loglog(lags, response_func, 'k-', linewidth=3, label='R(ℓ) Average', alpha=0.9)\n",
    "\n",
    "plt.xlabel('Time (Trades)', fontsize=12)\n",
    "plt.ylabel('R(ℓ,V) / ln(V)', fontsize=12)\n",
    "plt.title('Volume Conditioned Response R(ℓ,V)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71594e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_correlation(signs, log_vols, lags):\n",
    "\n",
    "    mean_log_vol = np.mean(log_vols)\n",
    "    mean_sign = np.mean(signs)\n",
    "    mean_sign_squared = mean_sign**2\n",
    "\n",
    "    C0 = np.zeros(len(lags))  # Basic sign correlation\n",
    "    C1 = np.zeros(len(lags))  # Cross correlation with volume\n",
    "    C2 = np.zeros(len(lags))  # Volume-weighted correlation\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        print(f\"  Lag {lag}/{max_lag}\")\n",
    "            \n",
    "        idx_present = slice(None, -lag)  # [0, 1, ..., n-lag-1]  \n",
    "        idx_future = slice(lag, None)    # [lag, lag+1, ..., n-1]\n",
    "        \n",
    "        signs_present = signs[idx_present]\n",
    "        signs_future = signs[idx_future] \n",
    "        log_vols_present = log_vols[idx_present]\n",
    "        log_vols_future = log_vols[idx_future]\n",
    "        \n",
    "        # C0(l) = <ε_{n+l} ε_n> - <ε_n>²\n",
    "        C0[i] = np.mean(signs_future * signs_present) - mean_sign_squared\n",
    "        \n",
    "        # C1(l) = <ε_{n+l} ε_n ln V_n>\n",
    "        C1[i] = np.mean(signs_future * signs_present * log_vols_present)\n",
    "        \n",
    "        # C2(l) = <ε_{n+l} ln V_{n+l} ε_n ln V_n>\n",
    "        C2[i] = np.mean(signs_future * log_vols_future * signs_present * log_vols_present)\n",
    "\n",
    "    return {\n",
    "        'lags': lags,\n",
    "        'C0': C0,\n",
    "        'C1': C1, \n",
    "        'C2': C2,\n",
    "        'mean_log_vol': mean_log_vol\n",
    "    }\n",
    "\n",
    "def power_law(x: np.ndarray, A: float, gamma: float) -> np.ndarray:\n",
    "    return A * np.power(x, -gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = sign_correlation(signs, log_volumes, lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lag = 10\n",
    "\n",
    "mask = (correlations['lags'] >= min_lag) & (correlations['lags'] <= max_lag) & (correlations['C0'] > 0)\n",
    "\n",
    "# Linear fit: log(y) = log(A) - gamma * log(x)\n",
    "if np.sum(mask) > 5:\n",
    "    log_lags = np.log(lags[mask])\n",
    "    log_corr = np.log(correlations['C0'][mask])\n",
    "    \n",
    "    coeffs = np.polyfit(log_lags, log_corr, 1)\n",
    "    gamma = -coeffs[0]\n",
    "    A = np.exp(coeffs[1])\n",
    "    \n",
    "    print(f\"Ajustement C₀(ℓ) ∝ ℓ^(-{gamma:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple correlation functions plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "lags = correlations['lags']\n",
    "C0 = correlations['C0'] \n",
    "C1 = correlations['C1']\n",
    "C2 = correlations['C2']\n",
    "mean_log_vol = correlations['mean_log_vol']\n",
    "\n",
    "ax.loglog(lags, C0, 'o-', label='C₀(ℓ)', color='blue', markersize=3, linewidth=1.5)\n",
    "ax.loglog(lags, np.abs(C1), 's-', label='C₁(ℓ)', color='red', markersize=3, linewidth=1.5)  \n",
    "ax.loglog(lags, C2, '^-', label='C₂(ℓ)', color='green', markersize=3, linewidth=1.5)\n",
    "\n",
    "theoretical_C1 = mean_log_vol * C0\n",
    "theoretical_C2 = mean_log_vol**2 * C0\n",
    "\n",
    "valid_mask = C0 > 0\n",
    "ax.loglog(lags[valid_mask], np.abs(theoretical_C1[valid_mask]), ':', \n",
    "         color='red', alpha=0.7, linewidth=2, label='⟨ln V⟩ C₀(ℓ)')\n",
    "ax.loglog(lags[valid_mask], theoretical_C2[valid_mask], ':', \n",
    "         color='green', alpha=0.7, linewidth=2, label='⟨ln V⟩² C₀(ℓ)')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_xlabel('Time (trades)', fontsize=14)\n",
    "ax.set_ylabel('C(ℓ)', fontsize=14) \n",
    "ax.set_title('Sign Correlation Functions (Bouchaud Analysis)', fontsize=16)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xlim(1, max(lags))\n",
    "\n",
    "textstr = f'⟨ln V⟩ = {mean_log_vol:.2f}'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=12,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61044a",
   "metadata": {},
   "source": [
    "## 2. Propagator Model\n",
    "- Propagator Model: P(t) = ∑G(t-s)ε(s)\n",
    "- Temporal impact analysis (temporary vs permanent)\n",
    "- Trade information content effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62785dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.24      # Sign correlation decay exponent\n",
    "C0 = 0.20         # Correlation amplitude  \n",
    "Gamma0 = 2.8e-3   # Overall scaling\n",
    "l0 = 20           # Short-time cutoff (trades)\n",
    "\n",
    "# Critical exponent for diffusive prices\n",
    "beta_c = (1 - gamma) / 2\n",
    "print(f\"Critical exponent βc = {beta_c:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d2c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(t) = Σ G₀(t-s) ε(s) ln(V(s))\n",
    "def propagator(t, t0=20, beta=0.4, Gamma0=0.001):\n",
    "    \"\"\"G₀(t) = Γ₀ * t₀^β / (t₀ + t)^β\"\"\"\n",
    "    return Gamma0 * (t0**beta) / ((t0 + t)**beta)\n",
    "\n",
    "# Theoretical response function\n",
    "def theo_response(lags, C0, gamma, t0=20, beta=0.4, Gamma0=0.001):\n",
    "    \"\"\"R(ℓ) using Eq. 17 from the paper\"\"\"\n",
    "    R_theory = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        # Direct term\n",
    "        term1 = propagator(lag, t0, beta, Gamma0)\n",
    "        \n",
    "        # Correlation terms\n",
    "        term2 = 0\n",
    "        for n in range(1, min(lag, 100)):\n",
    "            \n",
    "            if n-1 < len(correlations['C0']):\n",
    "                corr = correlations['C0'][n-1]  # Use calculated C0(n)\n",
    "            else:\n",
    "                corr = C0 / (n**gamma)\n",
    "\n",
    "            term2 += propagator(lag - n, t0, beta, Gamma0) * corr\n",
    "        \n",
    "        R_theory.append(term1 + term2)\n",
    "    \n",
    "    return np.array(R_theory)\n",
    "\n",
    "def fit_propagator(params):\n",
    "    t0, beta, Gamma0 = params\n",
    "    if beta <= 0 or beta >= 1 or t0 <= 0 or Gamma0 <= 0:\n",
    "        return 1e6\n",
    "    \n",
    "    R_pred = theo_response(lags[:len(response_func)], C0, gamma, t0, beta, Gamma0)\n",
    "    return np.sum((response_func - R_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_values = [0.36, 0.38, 0.40, 0.42, 0.44]  # Around βc\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "# Calculate for different beta values using the existing method\n",
    "responses = {}\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, beta in enumerate(beta_values):\n",
    "    print(f\"β = {beta}:\")\n",
    "    R = theo_response(lags, C0, gamma, l0, beta, Gamma0)\n",
    "    responses[beta] = R\n",
    "    \n",
    "    # Plot each response function\n",
    "    plt.loglog(lags, R, '--', color=colors[i % len(colors)], \n",
    "               linewidth=2, alpha=0.7, label=f'Theory β={beta:.2f}')\n",
    "\n",
    "# Plot the empirical response function for comparison  \n",
    "plt.loglog(lags, response_func, 'ko-', linewidth=3, markersize=4, \n",
    "           label='Empirical R(ℓ)', alpha=0.8)\n",
    "\n",
    "# Highlight the critical beta\n",
    "plt.loglog(lags, responses[beta_c], 'b-', linewidth=4, \n",
    "           alpha=0.9, label=f'Critical β={beta_c:.3f}')\n",
    "\n",
    "plt.xlabel('Time (Trades)', fontsize=14)\n",
    "plt.ylabel('R(ℓ)', fontsize=14)\n",
    "plt.title('Response Function: Theory vs Empirical', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlim(1, max(lags))\n",
    "\n",
    "# Add parameter information\n",
    "textstr = f'γ = {gamma:.2f}\\nC₀ = {C0:.2f}\\nΓ₀ = {Gamma0:.1e}\\nl₀ = {l0}'\n",
    "props = dict(boxstyle='round', facecolor='lightblue', alpha=0.8)\n",
    "plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=11,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison statistics\n",
    "print(\"\\nFit quality comparison:\")\n",
    "for beta in beta_values:\n",
    "    mse = np.mean((response_func - responses[beta])**2)\n",
    "    print(f\"β = {beta:.2f}: MSE = {mse:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455486da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot response functions for different beta values\n",
    "for beta, color in zip(beta_values, colors):\n",
    "    R = responses[beta]\n",
    "    ax1.plot(lags, R * 1000, label=f'β={beta}', color=color, alpha=0.8, linewidth=2)\n",
    "\n",
    "ax1.axvline(x=100, color='gray', linestyle='--', alpha=0.5, label='~100 trades')\n",
    "ax1.axvline(x=1000, color='gray', linestyle=':', alpha=0.5, label='~1000 trades')\n",
    "\n",
    "ax1.set_xlabel('Time (Trades)', fontsize=12)\n",
    "ax1.set_ylabel('R(ℓ) × 1000', fontsize=12)\n",
    "ax1.set_title('Response Function for Different β Values\\n(Reproducing Bouchaud Fig. 9)', fontsize=14)\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "textstr = f'''Key Insights:\n",
    "• βc = {beta_c:.3f} for γ = {gamma}\n",
    "• β < βc: Upward trend\n",
    "• β > βc: Downward trend  \n",
    "• β ≈ βc: Nearly constant'''\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "ax1.text(0.02, 0.98, textstr, transform=ax1.transAxes, fontsize=10,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Calculate propagator for extended range\n",
    "lags_extended = np.arange(1, 10000)\n",
    "G0_fit = np.array([propagator(l, 0.42) for l in lags_extended])\n",
    "G0_critical = np.array([propagator(l, beta_c) for l in lags_extended])\n",
    "\n",
    "# Plot on log-log scale\n",
    "ax2.loglog(lags_extended, G0_fit, label='G₀ fit (β=0.42)', color='green', linewidth=2)\n",
    "ax2.loglog(lags_extended, G0_critical, label=f'G₀ critical (β={beta_c:.3f})', \n",
    "           color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Add power-law reference lines\n",
    "ax2.loglog(lags_extended, 1e-3 * lags_extended**(-0.42), 'k:', alpha=0.5, \n",
    "           label='l^(-0.42)')\n",
    "ax2.loglog(lags_extended, 1e-3 * lags_extended**(-beta_c), 'k--', alpha=0.5, \n",
    "           label=f'l^(-{beta_c:.2f})')\n",
    "\n",
    "ax2.set_xlabel('ℓ (trades)', fontsize=12)\n",
    "ax2.set_ylabel('G₀(ℓ)', fontsize=12)\n",
    "ax2.set_title('Bare Propagator G₀(ℓ)\\n(Reproducing Bouchaud Fig. 10)', fontsize=14)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"• Sign correlation decay: γ = {gamma}\")\n",
    "print(f\"• Correlation amplitude: C₀ = {C0}\")\n",
    "print(f\"• Overall scaling: Γ₀ = {Gamma0}\")\n",
    "print(f\"• Short-time cutoff: ℓ₀ = {l0}\")\n",
    "\n",
    "print(f\"• Critical exponent: βc = (1-γ)/2 = {beta_c:.3f}\")\n",
    "print(f\"• Critical condition: 2β + γ = {2*beta_c + gamma:.1f}\")\n",
    "\n",
    "print(f\"• For β = {beta_c:.3f} (critical): R(ℓ) nearly constant\")\n",
    "print(f\"• For β = 0.42 (best fit): R(ℓ) shows realistic max/decay\")\n",
    "\n",
    "print(f\"\\nPhysical Interpretation:\")\n",
    "print(f\"• Market at critical point balancing:\")\n",
    "print(f\"  - Long-range correlations (super-diffusion)\")\n",
    "print(f\"  - Impact decay (sub-diffusion)\")\n",
    "print(f\"• Result: Diffusive (random walk) price process\")\n",
    "\n",
    "R_max_idx = np.argmax(responses[0.42])\n",
    "R_max_lag = lags[R_max_idx]\n",
    "R_max_value = responses[0.42][R_max_idx]\n",
    "\n",
    "print(f\"• Maximum response at ℓ ≈ {R_max_lag} trades\")\n",
    "print(f\"• Maximum value: R_max = {R_max_value*1000:.3f} × 10⁻³\")\n",
    "print(f\"• Ratio R_max/R(1) = {R_max_value/responses[0.42][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e52c9",
   "metadata": {},
   "source": [
    "## 3. ML Implementation\n",
    "- Features: Volatility metrics, volume patterns, spreads, order book imbalance, decay patterns from propagator analysis\n",
    "- Target: Direct price impact ΔP prediction\n",
    "- Models: Compare ML predictions vs Square-root law vs Propagator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "517a7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    params = [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "    return params\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict_single(params, x):\n",
    "    \"\"\"Predict single sample (regression output)\"\"\"\n",
    "    activations = x\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "    \n",
    "    # Final layer (no activation for regression)\n",
    "    final_w, final_b = params[-1]\n",
    "    output = jnp.dot(final_w, activations) + final_b\n",
    "    return output[0]  # Return scalar\n",
    "\n",
    "# Vectorized prediction\n",
    "predict_batch = vmap(predict_single, in_axes=(None, 0))\n",
    "\n",
    "def mse_loss(params, x_batch, y_batch):\n",
    "    predictions = predict_batch(params, x_batch)\n",
    "    return jnp.mean((predictions - y_batch) ** 2)\n",
    "\n",
    "@jit\n",
    "def update_step(params, x_batch, y_batch, learning_rate):\n",
    "    grads = grad(mse_loss)(params, x_batch, y_batch)\n",
    "    return [(w - learning_rate * dw, b - learning_rate * db)\n",
    "            for (w, b), (dw, db) in zip(params, grads)]\n",
    "\n",
    "def features(trades_df, window=20):\n",
    "    \"\"\"Create simple trading features\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Basic features\n",
    "    features['log_volume'] = jnp.log(trades_df['volume_normalized'] + 1e-8)\n",
    "    features['trade_sign'] = trades_df['trade_sign']\n",
    "    features['price'] = trades_df['price']\n",
    "    \n",
    "    # Rolling features\n",
    "    features['volatility'] = trades_df['price'].rolling(window).std().fillna(0)\n",
    "    features['volume_ma'] = trades_df['volume_normalized'].rolling(window).mean().fillna(0)\n",
    "    \n",
    "    return features.values\n",
    "\n",
    "def target(trades_df, horizon=5):\n",
    "    \"\"\"Create prediction target (signed price impact)\"\"\"\n",
    "    price_change = trades_df['price'].shift(-horizon) - trades_df['price']\n",
    "    signed_impact = price_change * trades_df['trade_sign']\n",
    "    return signed_impact.fillna(0).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "081b46e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_root_baseline(volumes, signs):\n",
    "    \"\"\"Simple Square-Root Law baseline\"\"\"\n",
    "    return 0.001 * jnp.sqrt(volumes) * signs\n",
    "\n",
    "def propagator_baseline(volumes, signs, horizon=5):\n",
    "    \"\"\"Simple Propagator baseline\"\"\" \n",
    "    # G0(t) = Gamma0 * t0^beta / (t0 + t)^beta\n",
    "    Gamma0, t0, beta = 0.001, 20, 0.38\n",
    "    G0 = Gamma0 * (t0**beta) / ((t0 + horizon)**beta)\n",
    "    return G0 * jnp.log(volumes + 1e-8) * signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a47d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid samples: 7408515\n",
      "Features: ['log_volume', 'trade_sign', 'price', 'volume_ma_20', 'price_volatility']\n",
      "Train: (5926812, 5), Test: (1481703, 5)\n"
     ]
    }
   ],
   "source": [
    "# Create features using numpy (not JAX) \n",
    "features = pd.DataFrame()\n",
    "features['log_volume'] = np.log(trades_clean['volume_normalized'] + 1e-8)\n",
    "features['trade_sign'] = trades_clean['trade_sign']\n",
    "features['price'] = trades_clean['price']\n",
    "features['volume_ma_20'] = trades_clean['volume_normalized'].rolling(20).mean()\n",
    "features['price_volatility'] = trades_clean['price'].rolling(20).std()\n",
    "\n",
    "# Create target\n",
    "target = (trades_clean['price'].shift(-5) - trades_clean['price']) * trades_clean['trade_sign']\n",
    "\n",
    "# Clean data\n",
    "valid_idx = ~(features.isna().any(axis=1) | target.isna())\n",
    "X = features[valid_idx].values\n",
    "y = target[valid_idx].values\n",
    "\n",
    "print(f\"Valid samples: {len(X)}\")\n",
    "print(f\"Features: {features.columns.tolist()}\")\n",
    "\n",
    "# Train/test split\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to JAX arrays\n",
    "X_train = jnp.array(X_train.astype(np.float32))\n",
    "X_test = jnp.array(X_test.astype(np.float32))\n",
    "y_train = jnp.array(y_train.astype(np.float32))\n",
    "y_test = jnp.array(y_test.astype(np.float32))\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: [5, 16, 8, 1]\n",
      "Epoch 0: Train Loss: 2.284898, Test Loss: 0.612426\n",
      "Epoch 100: Train Loss: 2.260917, Test Loss: 0.576264\n"
     ]
    }
   ],
   "source": [
    "# Network architecture\n",
    "layer_sizes = [X_train.shape[1], 16, 8, 1]  # input_dim -> 16 -> 8 -> 1\n",
    "learning_rate = 0.001\n",
    "n_epochs = 500\n",
    "batch_size = 256\n",
    "\n",
    "print(f\"Architecture: {layer_sizes}\")\n",
    "\n",
    "# Initialize network\n",
    "key = random.PRNGKey(42)\n",
    "params = init_network_params(layer_sizes, key)\n",
    "\n",
    "# Training loop\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Mini-batch training\n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        X_batch = X_train[start_idx:end_idx]\n",
    "        y_batch = y_train[start_idx:end_idx]\n",
    "        \n",
    "        params = update_step(params, X_batch, y_batch, learning_rate)\n",
    "    \n",
    "    train_loss = mse_loss(params, X_train, y_train)\n",
    "    test_loss = mse_loss(params, X_test, y_test)\n",
    "    print(f\"Epoch {epoch}: Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e7db90c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m nn_pred \u001b[38;5;241m=\u001b[39m predict_batch(\u001b[43mparams\u001b[49m, X_test)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Traditional baselines (using existing functions)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_volumes \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mexp(X_test[:, \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Convert back from log_volume\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "nn_pred = predict_batch(params, X_test)\n",
    "\n",
    "# Traditional baselines (using existing functions)\n",
    "test_volumes = jnp.exp(X_test[:, 0])  # Convert back from log_volume\n",
    "test_signs = X_test[:, 1]  # trade_sign\n",
    "\n",
    "sqrt_pred = square_root_baseline(test_volumes, test_signs)\n",
    "prop_pred = propagator_baseline(test_volumes, test_signs)\n",
    "\n",
    "# Calculate metrics\n",
    "def calc_r2(y_true, y_pred):\n",
    "    ss_res = jnp.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = jnp.sum((y_true - jnp.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "print(\"\\nMODEL PERFORMANCE:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "models = {\n",
    "    'Neural Network': nn_pred,\n",
    "    'Square Root Law': sqrt_pred[:len(y_test)],\n",
    "    'Propagator Model': prop_pred[:len(y_test)]\n",
    "}\n",
    "\n",
    "for name, pred in models.items():\n",
    "    mse = jnp.mean((y_test - pred) ** 2)\n",
    "    r2 = calc_r2(y_test, pred)\n",
    "    print(f\"{name:15}: MSE = {mse:.2e}, R² = {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de72236",
   "metadata": {},
   "source": [
    "## 4. Regime-Dependent Analysis\n",
    "- Identify market conditions where traditional models underperform\n",
    "- Cross-validation framework across different market regimes\n",
    "- Performance comparison metrics focusing on model failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b08e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
